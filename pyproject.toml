[project]
name = "litellm"
version = "1.80.5"
description = "Library to easily interface with LLM API providers"
authors = [
    {name = "BerriAI"}
]
license = {text = "MIT"}
readme = "README.md"
requires-python = ">=3.9,<4.0"
dependencies = [
    "fastuuid>=0.13.0",
    "httpx>=0.23.0",
    "openai>=2.8.0",
    "python-dotenv>=0.2.0",
    "tiktoken>=0.7.0",
    "importlib-metadata>=6.8.0",
    "tokenizers",
    "click",
    "jinja2>=3.1.2,<4.0",
    "aiohttp>=3.10",
    "pydantic>=2.5.0,<3.0",
    "jsonschema>=4.22.0,<5.0",
]

[project.optional-dependencies]
utils = [
    "numpydoc",
]
proxy = [
    "gunicorn>=23.0.0,<24.0",
    "uvicorn>=0.31.1,<0.32.0",
    "uvloop>=0.21.0,<0.22.0; sys_platform != 'win32'",
    "fastapi>=0.120.1",
    "backoff",
    "pyyaml>=6.0.1,<7.0",
    "rq",
    "orjson>=3.9.7,<4.0",
    "apscheduler>=3.10.4,<4.0",
    "fastapi-sso>=0.16.0,<0.17.0",
    "PyJWT>=2.10.1,<3.0; python_version >= '3.9'",
    "python-multipart>=0.0.18,<0.1.0",
    "cryptography",
    "pynacl>=1.5.0,<2.0",
    "websockets>=13.1.0,<14.0",
    "boto3==1.36.0",
    "azure-identity>=1.15.0,<2.0; python_version >= '3.9'",
    "azure-storage-blob>=12.25.1,<13.0",
    "mcp>=1.21.2,<2.0; python_version >= '3.10'",
    "litellm-proxy-extras==0.4.6",
    "litellm-enterprise==0.1.22",
    "rich==13.7.1",
    "polars>=1.31.0,<2.0; python_version >= '3.10'",
    "soundfile>=0.12.1,<0.13.0",
]
extra_proxy = [
    "prisma==0.11.0",
    "azure-identity>=1.15.0,<2.0; python_version >= '3.9'",
    "azure-keyvault-secrets>=4.8.0,<5.0",
    "google-cloud-kms>=2.21.3,<3.0",
    "google-cloud-iam>=2.19.1,<3.0",
    "resend>=0.8.0",
    "redisvl>=0.4.1,<0.5.0; python_version >= '3.9' and python_version < '3.14'",
]
caching = [
    "diskcache>=5.6.1,<6.0",
]
semantic-router = [
    "semantic-router>=0.1.12; python_version >= '3.9' and python_version < '3.14'",
]
mlflow = [
    "mlflow>3.1.4; python_version >= '3.10'",
]
dev = [
    "flake8>=6.1.0,<7.0",
    "black>=23.12.0,<24.0",
    "mypy>=1.0,<2.0",
    "pytest>=7.4.3,<8.0",
    "pytest-mock>=3.12.0,<4.0",
    "pytest-asyncio>=0.21.1,<0.22.0",
    "requests-mock>=1.12.1,<2.0",
    "responses>=0.25.7,<0.26.0",
    "respx>=0.22.0,<0.23.0",
    "ruff>=0.1.0,<0.2.0",
    "types-requests",
    "types-setuptools",
    "types-redis",
    "types-PyYAML",
    "opentelemetry-api==1.25.0",
    "opentelemetry-sdk==1.25.0",
    "opentelemetry-exporter-otlp==1.25.0",
    "langfuse>=2.45.0,<3.0",
    "fastapi-offline>=1.7.3,<2.0",
]
proxy-dev = [
    "prisma==0.11.0",
    "hypercorn>=0.15.0,<0.16.0",
    "prometheus-client==0.20.0",
    "opentelemetry-api==1.25.0",
    "opentelemetry-sdk==1.25.0",
    "opentelemetry-exporter-otlp==1.25.0",
    "azure-identity>=1.15.0,<2.0; python_version >= '3.9'",
]

[project.urls]
homepage = "https://litellm.ai"
repository = "https://github.com/BerriAI/litellm"
documentation = "https://docs.litellm.ai"

[project.scripts]
litellm = "litellm:run_server"
litellm-proxy = "litellm.proxy.client.cli:cli"

[tool.setuptools]
packages = ["litellm"]
include-package-data = true

[tool.setuptools.package-data]
litellm = ["py.typed"]

[tool.isort]
profile = "black"

[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.commitizen]
version = "1.80.5"
version_files = [
    "pyproject.toml:^version"
]

[tool.mypy]
plugins = "pydantic.mypy"

[tool.pytest.ini_options]
asyncio_mode = "auto"
markers = [
    "asyncio: mark test as an asyncio test",
]
